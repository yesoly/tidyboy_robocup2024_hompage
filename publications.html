<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">

<head>
<title>team TIDYBOY Homepage</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<link href="global.css" rel="stylesheet" type="text/css" />
</head>
<body>

	<div id="Container">
		<div id="Top">
		  <img src="images/assets/PNU.svg" width="75" height="50" class="logo" /><img src="images/assets/snu.png" width="50" height="50" class="logo" />	
		  <h1>Team TIDYBOY</h1>
		  <h2>Biointelligence Lab, Seoul National University</h2>
		  <h2>Autonomous Robotics and Artificial Intelligence Lab, Pusan National University</h2>
		</div>
		
		<div id="nav">
			<ul>
			  <li><a href="index.html">Home</a></li>
			  <li><a href="members.html">Members</a></li>
			  <li><a href="media1.html">Qualification Video</a></li>
			  <li><a href="media2.html">Other Videos</a></li>
			  <li><a href="softwares.html">Open-Source</a></li>
			  <li class="last"><a href="publications.html">Publications</a></li>
			</ul>
			</div>
  
<div id="MainText">
	<SPAN class="title"><h1>Selected Publications</h1></SPAN>

	<!-- ICRA 2024 수진 -->
	<div id="session">
		<div id="publish_left">
			<b>HAPFI: History-Aware Planning based on Fused Information (ICRA 2024)</b><br>
			<UL style="font-size: 15px;"type="square">
				<LI>Suyeon Shin*, Sujin Jeon* and Byoung-Tak Zhang</LI>
				<LI>published in Proceedings of the 2024 IEEE International Conference on Robotics and Automation </LI>
				<div id="abstract">
				<LI>
					<div style="margin: 3px; margin-left: 5px;">
					<b>Abstract:</b> This paper propose History-Aware Planning based on Fused Information(HAPFI),
					effectively leveraging the historical data from diverse modalities that agents collect while interacting with the environment.
					</div>
				</LI>
				</div>
			</UL>
		</div>	
		<div id="publish_right">
			<img src="images/papers/ICRA_SYShin.png" style="height:140px; margin-top: 5px; width:220px; display: block;">
			<div id="btn">
				<a href="" class="w-btn-outline" style="font-size: 12px;">
					Paper
				</a>
			</div>
		</div>
	</div>
	

	<!-- ICRA 2024 승현 -->
	<div id="session">
		<div id="publish_left">
			<b>Multi-Object RANSAC: Efficient Plane Clustering method in a Clutter (ICRA 2024)</b><br>
			<UL style="font-size: 15px;"type="square">
				<LI>Seunghyeon Lim, Youngjae Yoo, Lee Jun Ki and Byoung-Tak Zhang</LI>
				<LI>published in Proceedings of the 2024 IEEE International Conference on Robotics and Automation </LI>
				<div id="abstract">
				<LI>
					<div style="margin: 3px; margin-left: 5px;">
					<b>Abstract:</b> This paper propose a novel method for plane clustering specialized in cluttered scenes using an RGBD camera and validate its effectiveness through robot grasping
					experiments.
					</div>
				</LI>
				</div>
			</UL>
		</div>	
		<div id="publish_right">
			<img src="images/papers/ICRA_SHLim.png" style="height:140px; margin-top: 5px; width:220px; display: block;">
			<div id="btn">
				<a href="" class="w-btn-outline" style="font-size: 12px;">
					Paper
				</a>
			</div>
		</div>
	</div>

	<!-- ICRA 2024 기천 -->
	<div id="session">
		<div id="publish_left">
			<b>PROGrasp: Pragmatic Human-Robot Communication for Object Grasping (ICRA 2024)</b><br>
			<UL style="font-size: 15px;"type="square">
				<LI>Gi-Cheon Kang, Junghyun Kim, Jaein Kim and Byoung-Tak Zhang</LI>
				<LI>published in Proceedings of the 2024 IEEE International Conference on Robotics and Automation </LI>
				<div id="abstract">
				<LI>
					<div style="margin: 3px; margin-left: 5px;">
					<b>Abstract:</b> This paper introduce a new IOG task, Pragmatic-IOG, and the corresponding dataset, Intention-oriented Multi-modal Dialogue (IM-Dial).
					</div>
				</LI>
				</div>
			</UL>
		</div>	
		<div id="publish_right">
			<img src="images/papers/ICRA_GCKang.png" style="height:140px; margin-top: 5px; width:220px; display: block;">
			<div id="btn">
				<a href="https://arxiv.org/pdf/2309.07759.pdf" class="w-btn-outline" style="font-size: 12px;">
					Paper
				</a>
			</div>
		</div>
	</div>

	<!-- IROS 2023 정현 -->
	<div id="session">
		<div id="publish_left">
			<b>GVCCI: Lifelong Learning of Visual Grounding for Language-Guided Robotic Manipulation (IROS 2023)</b><br>
			<UL style="font-size: 15px;"type="square">
				<LI>Junghyun Kim, Gi-Cheon Kang, Jaein Kim, Suyeon Shin and Byoung-Tak Zhang</LI>
				<LI>published in Proceedings of IEEE/RSJ International Conference on Intelligent Robots and Systems</LI>
				<div id="abstract">
				<LI>
					<div style="margin: 3px; margin-left: 5px;">
					<b>Abstract:</b> This paper propose Grounding Vision to Ceaselessly Created Instructions (GVCCI), a lifelong learning framework for LGRM, which continuously learns VG without human supervision.
					</div>
				</LI>
				</div>
			</UL>
		</div>	
		<div id="publish_right">
			<img src="images/papers/IROS_JHKim.jpg" style="height:160px; margin-top: 5px; width:220px; display: block;">
			<div id="btn">
				<a href="https://github.com/JHKim-snu/GVCCI" class="w-btn-outline" style="font-size: 12px;">
					Github
				</a>
			</div>
		</div>
	</div>

	<!-- CVPR 2023 기천 -->
	<div id="session">
		<div id="publish_left">
			<b>The Dialog Must Go On:
				Improving Visual Dialog via Generative Self-Training (CVPR 2023)</b><br>
			<UL style="font-size: 15px;"type="square">
				<LI>Gi-Cheon Kang, Sungdong Kim, Jin-Hwa Kim, Donghyun Kwak and Byoung-Tak Zhang</LI>
				<LI>published in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR 2023)
				</LI>
				<div id="abstract">
				<LI>
					<div style="margin: 3px; margin-left: 5px;">
					<b>Abstract:</b> This paper presents a semi-supervised learning approach for visuallygrounded dialog, called Generative Self-Training (GST), to leverage unlabeled images on the Web.
					</div>
				</LI>
				</div>
			</UL>
		</div>	
		<div id="publish_right">
			<img src="images/papers/CVPR_GCKang.png" style="height:160px; margin-top: 5px; width:220px; display: block;">
			<div id="btn">
				<a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Kang_The_Dialog_Must_Go_On_Improving_Visual_Dialog_via_Generative_CVPR_2023_paper.pdf" class="w-btn-outline" style="font-size: 12px;">
					Paper
				</a>
			</div>
		</div>
	</div>

	<!-- ICRA 2023 재인 -->
	<div id="session">
		<div id="publish_left">
			<b>Robust Map Fusion with Visual Attention Utilizing Multi-agent Rendezvous (ICRA 2023)</b><br>
			<UL style="font-size: 15px;"type="square">
				<LI>Jaein Kim, Dong-Sig Han and Byoung-Tak Zhang</LI>
				<LI>published in Proceedings of the 2023 IEEE International Conference on Robotics and Automation </LI>
				<div id="abstract">
				<LI>
					<div style="margin: 3px; margin-left: 5px;">
					<b>Abstract:</b> This work proposes a novel map fusion system which robustly fuses local maps in challenging rendezvous that lack shared information. Our system utilizes the single visual perception from rendezvous and estimates the relative pose between agents with the DOPE.
					</div>
				</LI>
				</div>
			</UL>
		</div>	
		<div id="publish_right">
			<img src="images/papers/ICRA_JEKim.png" style="height:160px; margin-top: 5px; width:220px; display: block;">
			<div id="btn">
				<a href="https://ieeexplore.ieee.org/document/10161072" class="w-btn-outline" style="font-size: 12px;">
					Paper
				</a>
			</div>
		</div>
	</div>


	<!-- ICRA 2023 현서 -->
	<div id="session">
		<div id="publish_left">
			<b>EXOT: Exit-aware Object Tracker for Safe Robotic Manipulation of Moving Object (ICRA 2023)</b><br>
			<UL style="font-size: 15px;"type="square">
				<LI>Hyunseo Kim, Hye Jung Yoon, Minji Kim, Dong-Sig Han and Byoung-Tak Zhang</LI>
				<LI>published in Proceedings of the 2023 IEEE International Conference on Robotics and Automation </LI>
				<div id="abstract">
				<LI>
					<div style="margin: 3px; margin-left: 5px;">
					<b>Abstract:</b> This paper propose the EXit-aware Object Tracker (EXOT) on a robot hand camera that recognizes an object’s absence during manipulation. The robot decides whether to proceed by examining the tracker’s bounding box output containing the target object. 
					</div>
				</LI>
				</div>
			</UL>
		</div>	
		<div id="publish_right">
			<img src="images/papers/ICRA_HSKim.jpg" style="height:180px; margin-top: 5px; width:220px; display: block;">
			<div id="btn">
				<a href="https://ieeexplore.ieee.org/document/10160481" class="w-btn-outline" style="font-size: 12px;">
					Paper
				</a>
			</div>
		</div>
	</div>

	<!-- 여기서부턴 2023 홈페이지 그대로 -->

	<!-- ICRA 2022 GHLee -->
	<div id="session">
		<div id="publish_left">
			<b>From Scratch to Sketch: Deep Decoupled Hierarchical Reinforcement Learning for Robotic Sketching Agent (ICRA 2022)</b><br>
			<UL style="font-size: 15px;"type="square">
				<LI>Ganghun Lee, Minji Kim, Minsu Lee and Byoung-Tak Zhang</LI>
				<LI>published in Proceedings of the 2022 IEEE International Conference on Robotics and Automation </LI>
				<div id="abstract">
				<LI>
					<div style="margin: 3px; margin-left: 5px;">
					<b>Abstract:</b> This paper present an automated learning framework for a robotic sketching agent that is capable of training stroke-based rendering and motor control simultaneously.
					</div>
				</LI>
				</div>
			</UL>
		</div>	
		<div id="publish_right">
			<img src="images/papers/ICRA_GHLee.JPG" style="height:140px; margin-top: 5px; width:220px; display: block;">
			<div id="btn">
				<a href="https://bi.snu.ac.kr/Publications/Conferences/International/ICRA_GHLee.pdf" class="w-btn-outline" style="font-size: 12px;">
					Paper
				</a>
			</div>
		</div>
	</div>

	<!-- NIPS 2022 DSHan -->
	<div id="session">
		<div id="publish_left">
			<b>Robust Imitation via Mirror Descent Inverse Reinforcement Learning (NeurIPS 2022)</b><br>
			<UL style="font-size: 15px;"type="square">
				<LI>Dong-Sig Han, Hyunseo Kim, Hyundo Lee, Je-Hwan Ryu and Byoung-Tak Zhang</LI>
				<LI>published in Advances in Neural Information Processing Systems 35</LI>
				<div id="abstract">
				<LI>
					<div style="margin: 3px; margin-left: 5px;">
					<b>Abstract:</b> This paper proposes to predict a sequence of reward functions, which are iterative solutions for a constrained convex problem.
					</div>
				</LI>
				</div>
			</UL>
		</div>	
		<div id="publish_right">
			<img src="images/papers/NIPS_DSHan.JPG" style="height:140px; margin-top: 5px; width:220px; display: block;">
			<div id="btn">
				<a href="https://arxiv.org/abs/2210.11201" class="w-btn-outline" style="font-size: 12px;">
					Paper
				</a>
			</div>
		</div>
	</div>

	<!-- IJCAI 2022 CYLee -->
	<div id="session">
		<div id="publish_left">
			<b>PlaceNet: Neural Spatial Representation Learning with Multimodal Attention (IJCAI 2022)</b><br>
			<UL style="font-size: 15px;"type="square">
				<LI>Chung-Yeon Lee, Youngjae Yoo and Byoung-Tak Zhang</LI>
				<LI>published in 2022 International Joint Conference on Artificial Intelligence</LI>
				<div id="abstract">
				<LI>
					<div style="margin: 3px; margin-left: 5px;">
					<b>Abstract:</b> This paper present PlaceNet, a neural representation that learns through random observations in a self-supervised manner, and represents observed scenes with triplet attention using visual, topographic, and semantic cues.
					</div>
				</LI>
				</div>
			</UL>
		</div>	
		<div id="publish_right">
			<img src="images/papers/IJCAI_CYLee.JPG" style="height:140px; margin-top: 5px; width:220px; display: block;">
			<div id="btn">
				<a href="https://www.ijcai.org/proceedings/2022/0144.pdf" class="w-btn-outline" style="font-size: 12px;">
					Paper
				</a>
			</div>
		</div>
	</div>

	<!-- ICRA 2021 YJYoo -->
	<div id="session">
		<div id="publish_left">
			<b>Multimodal Anomaly Detection Based on Deep Auto-Encoder for Object Slip Perception of Mobile Manipulation Robots (ICRA 2021)</b><br>
			<UL style="font-size: 15px;"type="square">
				<LI>Youngjae Yoo, Chung-Yeon Lee and Byoung-Tak Zhang</LI>
				<LI>published in Proceedings of the 2021 IEEE International Conference on Robotics and Automation</LI>
				<div id="abstract">
				<LI>
					<div style="margin: 3px; margin-left: 5px;">
					<b>Abstract:</b> This paper present an anomaly detection method that utilizes multisensory data based on a deep autoencoder model. That integrates heterogeneous data streams collected from various robot sensors.
					</div>
				</LI>
				</div>
			</UL>
		</div>	
		<div id="publish_right">
			<img src="images/papers/ICRA_YJYoo.JPG" style="height:140px; margin-top: 5px; width:220px; display: block;">
			<div id="btn">
				<a href="https://bi.snu.ac.kr/Publications/Conferences/International/ICRA2021_YooLZ.pdf" class="w-btn-outline" style="font-size: 12px;">
					Paper
				</a>
			</div>
		</div>
	</div>

	<!-- NIPS 2021 KBKim -->
	<div id="session">
		<div id="publish_left">
			<b>Goal-Aware Cross-Entropy for Multi-Target Reinforcement Learning (NeurIPS 2021)</b><br>
			<UL style="font-size: 15px;"type="square">
				<LI>Kibeom Kim, Min Whoo Lee, Yoonsung Kim, Je-Hwan Ryu, Minsu Lee and Byoung-Tak Zhang</LI>
				<LI>published in Advances in Neural Information Processing Systems 34</LI>
				<div id="abstract">
				<LI>
					<div style="margin: 3px; margin-left: 5px;">
					<b>Abstract:</b> This paper propose goal-aware cross-entropy (GACE) loss, that can be utilized in a self-supervised way using auto-labeled goal states alongside reinforcement learning.
					</div>
				</LI>
				</div>
			</UL>
		</div>	
		<div id="publish_right">
			<img src="images/papers/NIPS_KBKim.JPG" style="height:140px; margin-top: 5px; width:220px; display: block;">
			<div id="btn">
				<a href="https://bi.snu.ac.kr/Publications/Conferences/International/NeurIPS_KBKim.pdf" class="w-btn-outline" style="font-size: 12px;">
					Paper
				</a>
			</div>
		</div>
	</div>

	<!-- CVPR 2020 ESKim -->
	<div id="session">
		<div id="publish_left">
			<b>Hypergraph Attention Networks for Multimodal Learning (CVPR 2020)</b><br>
			<UL style="font-size: 15px;"type="square">
				<LI>Eun-Sol Kim, Woo Young Kang, Kyoung-Woon On, Yu-Jung Heo and Byoung-Tak Zhang</LI>
				<LI>published in IEEE Conference on Computer Vision & Pattern Recognition</LI>
				<div id="abstract">
				<LI>
					<div style="margin: 3px; margin-left: 5px;">
					<b>Abstract:</b> This paper propose Hypergraph Attention Networks (HANs), which define a common semantic space among the modalities with symbolic graphs and extract a joint representation of the modalities based on a co-attention map constructed in the semantic space.
					</div>
				</LI>
				</div>
			</UL>
		</div>	
		<div id="publish_right">
			<img src="images/papers/CVPR_ESKim.JPG" style="height:140px; margin-top: 5px; width:220px; display: block;">
			<div id="btn">
				<a href="https://bi.snu.ac.kr/Publications/Conferences/International/CVPR2020_ESKimKOHZ.pdf" class="w-btn-outline" style="font-size: 12px;">
					Paper
				</a>
			</div>
		</div>
	</div>

	<!-- AAAI 2018 BJLee -->
	<div id="session">
		<div id="publish_left">
			<b>Perception-action-learning system for mobile social-service robots using deep learning (AAAI 2018)</b><br>
			<UL style="font-size: 15px;"type="square">
				<LI>Beom-Jin Lee, Jinyoung Cho, Chung-Yeon Lee, Kyung-Wha Park, Sungjun Choi, Cheolho Han, Dong-Sig Han, ... , and Byoung-Tak Zhang</LI>
				<LI>published in AAAI-18 Demonstrations Program</LI>
				<div id="abstract">
				<LI>
					<div style="margin: 3px; margin-left: 5px;">
					<b>Abstract:</b> This paper introduce a robust integrated perception-action-learning system for mobile social-service robots which significantly improves the performance in solving social service tasks
					</div>
				</LI>
				</div>
			</UL>
		</div>	
		<div id="publish_right">
			<img src="images/papers/AAAI_BJLee.JPG" style="height:140px; margin-top: 5px; width:220px; display: block;">
			<div id="btn">
				<a href="https://bi.snu.ac.kr/Publications/Conferences/International/AAAI2018Demo_BJLee.pdf" class="w-btn-outline" style="font-size: 12px;">
					Paper
				</a>
			</div>
		</div>
	</div>

	<!-- ICRA 2018 BJLee -->
	<div id="session" style="margin-bottom: 50px;">
		<div id="publish_left">
			<b>Robust Human Following by Deep Bayesian Trajectory Prediction for Home Service Robots (ICRA 2018)</b><br>
			<UL style="font-size: 15px;"type="square">
				<LI>Beom-Jin Lee, Jinyoung Cho, Christina Baek and Byoung-Tak Zhang</LI>
				<LI>published in Proceedings of the 2018 IEEE International Conference on Robotics and Automation</LI>
				<div id="abstract">
				<LI>
					<div style="margin: 3px; margin-left: 5px;">
					<b>Abstract:</b> This paper present a robust human following system that has the extendability to commercial service robot platforms having a RGB-D camera.
					</div>
				</LI>
				</div>
			</UL>
		</div>	
		<div id="publish_right">
			<img src="images/papers/ICRA_BJLee.JPG" style="height:140px; margin-top: 5px; width:220px; display: block;">
			<div id="btn">
				<a href="https://bi.snu.ac.kr/Publications/Conferences/International/ICRA2018_BJLee.pdf" class="w-btn-outline" style="font-size: 12px;">
					Paper
				</a>
			</div>
		</div>
	</div>
	<!-- ############################################################## RELATED WORKS ############################################################## -->
	<SPAN class="title"><h1>Related Works</h1></SPAN>
	<div id="session">
		<b>International Publications</b><br>
		<UL style="font-size: 15px;" type="square">
			<LI>Unveiling the Significance of Toddler-Inspired Reward Transition in Goal-Oriented Reinforcement Learning,
				J. Park, H.-B. Yoo, Y. Kim, M.-W. Lee, K. Kim, W.-S. Choi, M. Lee, B.-T. Zhang, In Proceedings of the 38th Annual AAAI Conference on Artificial Intelligence (AAAI 2024), 2024. (oral presentation)
				<a href="https://www.tandfonline.com/doi/abs/10.1080/01691864.2022.2111229" class="w-small-btn-outline" style="font-size: 11px;">Paper</a>
			</LI>
			<LI>DUEL: Duplicate Elimination on Active Memory for Self-supervised Class-imbalanced Learning,
				W.-S. Choi, H. Lee, D.-S. Han, J. Park, H. Koo, B.-T. Zhang, In Proceedings of the 38th Annual AAAI Conference on Artificial Intelligence (AAAI 2024), 2024.
				<a href="https://arxiv.org/abs/2210.17052" class="w-small-btn-outline" style="font-size: 11px;">Paper</a>
			</LI>
			<LI>Video Turing Test: A first step towards human-level AI,
				M. Lee, Y.-J. Heo, S. Choi, W.-S. Choi, B.-T. Zhang, AI Magazie, 44, 537-554, 2023.
				<a href="https://onlinelibrary.wiley.com/doi/10.1002/aaai.12128" class="w-small-btn-outline" style="font-size: 11px;">Paper</a>
			</LI>
			<LI>Neural Collage Transfer: Artistic Reconstruction via Material Manipulation,
				G. Lee, M. Kim, Y. Lee, M. Lee, B.-T. Zhang, Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV), 2023, pp. 2394-2405
				<a href="https://github.com/northadventure/CollageRL" class="w-small-btn-outline" style="font-size: 11px;">Paper</a>
			</LI>
			<LI>Learning Geometry-aware Representations by Sketching,
				H. Lee, I. Hwang, H. Go, W.-S. Choi, K. Kim, B.-T. Zhang, In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR 2023), June 2023.
				<a href="https://arxiv.org/abs/2304.08204" class="w-small-btn-outline" style="font-size: 11px;">Paper</a>
			</LI>
			<LI>On Discovery of Local Independence over Continuous Variables via Neural Contextual Decomposition, 
				I. Hwang, Y. Kwak, Y.-J. Song, B.-T. Zhang*, S. Lee*, Conference on Causal Learning and Reasoning (CLeaR), April 2023. (* equal contribution)
				<a href="https://openreview.net/pdf?id=-aFd28Uy9td" class="w-small-btn-outline" style="font-size: 11px;">Paper</a>
			</LI>
			<LI>Team Tidyboy at the WRS 2020: a modular software framework for home service robots,
				T. Kang, D. Song, J. Yi, J. Kim, C. Lee, Y. Yoo, M. Kim, ... , Advanced Robotics, 2022
				<a href="https://www.tandfonline.com/doi/abs/10.1080/01691864.2022.2111229" class="w-small-btn-outline" style="font-size: 11px;">Paper</a>
			</LI>
			<LI>Modal-specific Pseudo Query Generation for Video Corpus Moment Retrieval, 
				M. Jung, S. Choi, J. Kim, J.-H. Kim, B.-T. Zhang, In Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing (EMNLP 2022), December 2022.
				<a href="https://arxiv.org/abs/2210.12617" class="w-small-btn-outline" style="font-size: 11px;">Paper</a>
			</LI>	
			<LI>Task planning and motion control problems of service robots in human-centered environments,
				H. Moon, B.-T Zhang, and C Nam, Intelligent Service Robotics, 2022
				<a href="https://link.springer.com/article/10.1007/s11370-022-00442-6" class="w-small-btn-outline" style="font-size: 11px;">Paper</a>
			</LI>
			<LI>TARGET-ORIENTED REINFORCEMENT LEARNING METHOD AND APPARATUS FOR PERFORMING THE SAME
				B.-T. Zhang, K Kim, M Lee, MW Lee, Y Kim - US Patent App. 17/427,957, 2022
				<a href="https://www.freepatentsonline.com/y2022/0398830.html" class="w-small-btn-outline" style="font-size: 11px;">Patent</a>
			</LI>
			<LI>Smooth-Swap: A Simple Enhancement for Face-Swapping with Smoothness,
				J.-S.Kim, J.-H.Lee, B.-T.Zhang, The IEEE Conference on Computer Vision and Pattern Recognition (CVPR 2022), 2022.
				<a href="https://arxiv.org/abs/2112.05907" class="w-small-btn-outline" style="font-size: 11px;">Paper</a>
			</LI>
			<LI>SelecMix: Debiased Learning by Contradicting-pair Sampling,
				I.-W. Hwang, S.-J. Lee, Y.-H. Kwak, S.-J. Oh, D.Teney, J.-H. Kim, B.-T. Zhang, Advances in Neural Information Processing Systems 35 (NeurIPS 2022), 2022.
				<a href="https://arxiv.org/abs/2211.02291" class="w-small-btn-outline" style="font-size: 11px;">Paper</a>
			</LI>
			<LI>Toddler-Guidance Learning: Impacts of Critical Period on Multimodal AI Agents,
				J. -S. Park, K. -Y. Park, H. -S. Oh, G. -H. LEE, M. -S. LEE, Y. -K. Lee, B. -T. Zhang, 23rd ACM International Conference on Multimodal Interaction (ICMI 2021), 2021. (oral presentation, accept ratio= 13%)
				<a href="https://bi.snu.ac.kr/Publications/Conferences/International/ICMI_ParkJS.pdf" class="w-small-btn-outline" style="font-size: 11px;">Paper</a>
			</LI>
			<LI>Passive Versus Active: Frameworks of Active Learning for Linking Humans to Machines,
				J. Lim, H. Jo, B.-T. Zhang, J. Park, In Proceedings of the 43rd Annual Meeting of the Cognitive Science Society (CogSci 2021), 2021.
				<a href="https://bi.snu.ac.kr/Publications/Conferences/International/CogSci2021_JSLim.pdf" class="w-small-btn-outline" style="font-size: 11px;">Paper</a>
			</LI>
			<LI>Message Passing Adaptive Resonance Theory for Online Active Semi-supervised Learning,
				T. Kim, I. Hwang, H.-D. Lee, H. Kim, W.-S. Choi, J. Lim, B.-T. Zhang, The 38th International Conference on Machine Learning (ICML 2021), 2021.
				<a href="http://proceedings.mlr.press/v139/kim21e/kim21e.pdf" class="w-small-btn-outline" style="font-size: 11px;">Paper</a>
			</LI>
			<!-- 링크 안 열림 ㅠㅠ -->
			<LI>Effect of Active Pre-Learning Activities on Humans and Machines.
				J.-S. Lim, H.-Y. Jo, B.-T. Zhang, and J.-Y. Park, In Proceedings of the 42nd Annual Meeting of the Cognitive Science Society (CogSci 2020), 2020
				<a href="https://cogsci.mindmodeling.org/2020/papers/0867/0867.pdf" class="w-small-btn-outline" style="font-size: 11px;">Paper</a>
			</LI>
			<LI>Visual perception framework for an intelligent mobile robot,
				C.-Y. Lee, H.-D. Lee, I.-J. Hwang, B.-T. Zhang, 2020 17th International Conference on Ubiquitous Robots, 2020
				<a href="https://ieeexplore.ieee.org/abstract/document/9144932" class="w-small-btn-outline" style="font-size: 11px;">Paper</a>
			</LI>
			<LI>Label Propagation Adaptive Resonance Theory for Semi-Supervised Continuous Learning,
				T. Kim, I. Hwang, G.-C. Kang, W.-S. Choi, H. Kim and B.-T. Zhang, In Proceedings of the 45th International Conference on Acoustics, Speech, and Signal Processing (ICASSP 2020), May 2020. 
				<a href="https://bi.snu.ac.kr/Publications/Conferences/International/ICASSP2020_TKim.pdf" class="w-small-btn-outline" style="font-size: 11px;">Paper</a>
			</LI>
			<LI>CoDraw: Collaborative drawing as a testbed for grounded goal-driven communication,
				J.-H. Kim, N. Kitaev, X. Chen, M. Rohrbach, B.-T. Zhang, Y. Tian, and D. Batra, In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics (ACL 2019), pp. 6495-6513, 2019.
				<a href="https://bi.snu.ac.kr/Publications/Conferences/International/ACL2019_JHKimKCRZTB.pdf" class="w-small-btn-outline" style="font-size: 11px;">Paper</a>
			</LI>
			<LI>Simulating problem difficulty in arithmetic cognition through dynamic connectionist models,
				S. Cho, J. Lim, C. Hickey, J. A. Park, and B.-T. Zhang, In Proceedings of the 17th International Conference on Cognitive Modeling (ICCM 2019), pp. 29-34, 2019.
				<a href="https://bi.snu.ac.kr/Publications/Conferences/International/ICCM2019_SChoLHPZ.pdf" class="w-small-btn-outline" style="font-size: 11px;">Paper</a>
			</LI>
			<LI>Problem difficulty in arithmetic cognition: Humans and connectionist models,
				S. Cho, J. Lim, C. Hickey, and B.-T. Zhang, In Proceedings of the 41st Annual Meeting of the Cognitive Science Society (CogSci 2019), pp. 1506-1512, 2019. 
				<a href="https://bi.snu.ac.kr/Publications/Conferences/International/COGSCI2019_SChoLHZ.pdf" class="w-small-btn-outline" style="font-size: 11px;">Paper</a>
			</LI>
			<LI>VLAS: A vision-language-action integrated system for mobile social service robot,
				K.-W. Park, J.-Y. Choi, B.-J. Lee, C.-Y. Lee, I. Hwang, and B.-T. Zhang, Federated AI for Robotics Workshop (FAIR) 2018, IJCAI 2018, 2018
				<a href="https://bi.snu.ac.kr/Publications/Conferences/International/IJCAI2018_Workshop_FAIR_KWPark.pdf" class="w-small-btn-outline" style="font-size: 11px;">Paper</a>
			</LI>
		</UL>
		<br>
		<b>Korean Publications</b><br>
		<UL style="font-size: 15px;" type="square">
			<!-- 공간 정보 지도를 활용한 사람 보조 로봇 -->
			<LI>Robust Arm Robot Grasping System Using Greedy Grasping Algorithms, J.-O. Kim, H.-J. Yoon, Y.-S. Park and B.-T. Zhang, Proceedings of the Korean Information Science Society Conference (KSC 2023), 2023
				<a href="" class="w-small-btn-outline" style="font-size: 11px;">Paper</a>
			</LI>
			<!-- 그리디 파지 알고리즘을 활용한 강건한 암로봇 파지 시스템 -->
			<LI>Background Removal and Plane Clustering methods for Grasping Points Estimation using the Robotic Suction Gripper, S.-H. Lim, Y.-J. Yoo and B.-T. Zhang, Proceedings of the Korean Information Science Society Conference (KCC 2023), 2023
				<a href="" class="w-small-btn-outline" style="font-size: 11px;">Paper</a>
			</LI>
			
			<!-- 인간-로봇간의 자연스러운 대화를 위한 비동기적 프롬프트 탐지 
			<LI>인간-로봇간의 자연스러운 대화를 위한 비동기적 프롬프트 탐지, T.-Y. Kim, Y.-J. Yoo, J.-M. Park and B.-T. Zhang, Proceedings of the Korean Information Science Society Conference (KSC 2023), 2023
				<a href="" class="w-small-btn-outline" style="font-size: 11px;">Paper</a>
			</LI>
			-->

			<LI>Visual Perception-Based Assistive Mobile Robot System, H.-J. Yoon, J.-O. Kim, Y.-S. Park and B.-T. Zhang, Proceedings of the Korean Information Science Society Conference (KCC 2023), 2023
				<a href="https://www.dbpia.co.kr/journal/articleDetail?nodeId=NODE11488002" class="w-small-btn-outline" style="font-size: 11px;">Paper</a>
			</LI>
			<LI>Background Removal and Plane Clustering methods for Grasping Points Estimation using the Robotic Suction Gripper, S.-H. Lim, Y.-J. Yoo and B.-T. Zhang, Proceedings of the Korean Information Science Society Conference (KCC 2023), 2023
				<a href="https://www.dbpia.co.kr/journal/articleDetail?nodeId=NODE11488136" class="w-small-btn-outline" style="font-size: 11px;">Paper</a>
			</LI>
			<LI>RGB-D based 3D Unseen Object Detection for Robust Grasping of Mobile Manipulation Robot, Y.-J. Yoo, S.-J. Jeon and B.-T. Zhang, Proceedings of the Korean Information Science Society Conference (KCC 2023), 2023
				<a href="https://www.dbpia.co.kr/journal/articleDetail?nodeId=NODE11487964" class="w-small-btn-outline" style="font-size: 11px;">Paper</a>
			</LI>
			<LI>Autonomous Recycling Robot System Using Heuristic Grasping Algorithms, J.-O. Kim and B.-T. Zhang, Proceedings of the Korean Information Science Society Conference (KCC 2023), 2023
				<a href="https://www.dbpia.co.kr/journal/articleDetail?nodeId=NODE11488000" class="w-small-btn-outline" style="font-size: 11px;">Paper</a>
			</LI>
			<LI>A Simulated Learning Environment with Load Dataset Generation for Depalletizers, J.-M. Park, Y.-J. Yoo and B.-T. Zhang, Proceedings of the Korean Information Science Society Conference (KCC 2023), 2023
				<a href="https://www.dbpia.co.kr/journal/articleDetail?nodeId=NODE11487945" class="w-small-btn-outline" style="font-size: 11px;">Paper</a>
			</LI>

			<LI>Product Identification System based on Image FeatureSimilarity with Learning-free Model, Y.-J. Yoo, H.-J. Yoon, J.-O. Kim, Y.-S. Park, and B.-T. Zhang, Journal of Logistics Science & Technology, 3(2),36~55, 2022
				<a href="https://www.klst.or.kr/html/?pmode=archives&smode=view&TVIDX=7&THEIDX=24" class="w-small-btn-outline" style="font-size: 11px;">Paper</a>
			</LI>
			<LI>Cashier Free Counter System Using Artificial Intelligence with Robot Arm, H.-J. Yoon, Y.-S. Park, J.-O. Kim, Y.-J. Yoo and B.-T. Zhang, Proceedings of the Korean Information Science Society Conference (KSC 2022), 2022
				<a href="https://www.dbpia.co.kr/journal/articleDetail?nodeId=NODE11224093" class="w-small-btn-outline" style="font-size: 11px;">Paper</a>
			</LI>
			<!-- Upon Updated -->
			<LI>Indoor Path Planner of Mobile Manipulator Robot for Obstacle Avoidance and Removal,
				S.-H. Lim, Y.-J. Yoo, and B.-T. Zhang, Proceedings of the Korean Information Science Society Conference (KCC 2022), 2022
				<a href="https://www.dbpia.co.kr/pdf/pdfView.do?nodeId=NODE11121477" class="w-small-btn-outline" style="font-size: 11px;">Paper</a>
			</LI>
			<LI>Reset-free Multi-agent Reinforcement Learning Using Reversibility Estimation,
				M.-J.Kim, G.-H.Lee, and B.-T. Zhang, Proceedings of the Korean Information Science Society Conference (KCC 2022), 2022
				<a href="https://www.dbpia.co.kr/pdf/pdfView.do?nodeId=NODE11113610" class="w-small-btn-outline" style="font-size: 11px;">Paper</a>
			</LI>
			<LI>RSR: A Real-to-Sim-to-Real Robot Manipulation System Using VR,
				J.-M. Park, S.-J. Jeon, and B.-T. Zhang, Proceedings of the Korean Information Science Society Conference (KSC 2021), 2021
				<a href="https://bi.snu.ac.kr/Publications/Conferences/Domestic/KSC:KIMST2021/KSC_JMPark.pdf" class="w-small-btn-outline" style="font-size: 11px;">Paper</a>
			</LI>
			<LI>Adaptive Spatial Comprehension via Object Relationship Learning with Home Robot,
				J.-H. Kim, S.-J. Lee, Y.-J. Yoo, and B.-T. Zhang, Proceedings of the Korean Information Science Society Conference (KSC 2021), 2021
				<a href="https://bi.snu.ac.kr/Publications/Conferences/Domestic/KSC:KIMST2021/KSC_JHKim.pdf" class="w-small-btn-outline" style="font-size: 11px;">Paper</a>
			</LI>
			<LI>Deep RL-based Optimal Path Planning and Obstacle Avoidance for Mobile Robots,
				Y.-J. Song, Y.-J. Yoo, C.-Y. Lee, and B.-T. Zhang, Proceedings of the Korean Information Science Society Conference (KCC 2021), 2021
				<a href="https://bi.snu.ac.kr/Publications/Conferences/Domestic/KCC2021/KCC2021_YJSong.pdf" class="w-small-btn-outline" style="font-size: 11px;">Paper</a>
			</LI>
			<LI>Reset-free Competitive reinforcement learning to learn robotic manipulation skills,
				M.-J. Kim, G.-H. Lee, K.-B. Kim, M.-S. Lee, and B.-T. Zhang, Proceedings of the Korean Information Science Society Conference (KCC 2021), 2021
				<a href="https://bi.snu.ac.kr/Publications/Conferences/Domestic/KCC2021/KCC2021_MJKim.pdf" class="w-small-btn-outline" style="font-size: 11px;">Paper</a>
			</LI>
			<LI>One-Shot Object Detection based Service Application for Mobile Robot,
				S.-J. Lee, Y.-J. Yoo, and B.-T. Zhang, Proceedings of the Korean Information Science Society Conference (KCC 2021), 2021
				<a href="https://bi.snu.ac.kr/Publications/Conferences/Domestic/KCC2021/KCC2021_SJLee.pdf" class="w-small-btn-outline" style="font-size: 11px;">Paper</a>
			</LI>
			<LI>Multi-robot Map Merging with Pose Estimation and Image Generation based on Neural Network,
				J.-I. Kim, H.-D. Lee, G.-H. Lee, Y.-S. Kim, D.-S. Han, and B.-T. Zhang, Proceedings of the Korean Information Science Society Conference (KSC 2020), 2020
				<a href="https://bi.snu.ac.kr/Publications/Conferences/Domestic/KSC2020/KSC2020_JYKimLLKHZ.pdf" class="w-small-btn-outline" style="font-size: 11px;">Paper</a>
			</LI>
			<LI>Autoencoder-based Multimodal Anomaly Detection for Mobile Manipulation Robots,
				Y.-J. Yoo, C.-Y. Lee, and B.-T. Zhang, Proceedings of the Korean Information Science Society Conference (KCC 2020), 2020
				<a href="https://bi.snu.ac.kr/Publications/Conferences/Domestic/KCC2020/KCC2020_YJYooLZ.pdf" class="w-small-btn-outline" style="font-size: 11px;">Paper</a>
			</LI>
			<LI>Extrinsic Calibration for Multiple Cameras without Target Locations
				Y.-S. Kim and B.-T. Zhang, 2019 Proceedings of the Korean Information Science Society Conference (KSC 2019), 2019
				<a href="https://bi.snu.ac.kr/~scai/Publications/Conferences/Domestic/KSC2019/KSC2019_YSKimZ.pdf" class="w-small-btn-outline" style="font-size: 11px;">Paper</a>
			</LI>
			<LI>Learning with target classification auxiliary task for semantic navigation,
				K.-B. Kim, and B.-T. Zhang, 2019 Proceedings of the Korean Information Science Society Conference (KSC 2019), 2019
				<a href="https://bi.snu.ac.kr/Publications/Conferences/Domestic/KSC2019/KSC2019_KBKimZ.pdf" class="w-small-btn-outline" style="font-size: 11px;">Paper</a>
			</LI>
			<LI>Best Base Placement and Safe Arm Trajectory Execution using Reachability for Domestic Robots to Optimally Interact with Objects,
				J.-I. Kim, B.-J. Lee, and B.-T. Zhang, 2019 Proceedings of the Korean Information Science Society Conference (KSC 2019), 2019
				<a href="https://bi.snu.ac.kr/~scai/Publications/Conferences/Domestic/KSC2019/KSC2019_JIKimLZ.pdf" class="w-small-btn-outline" style="font-size: 11px;">Paper</a>
			</LI>
			<LI>An Automatic Dough Molding System based on Integration of Deep Learning Techniques Applicable to Commercial Manipulator Robots,
				J.-I. Kim, B.-J. Lee, and B.-T. Zhang, 2019 Proceedings of the Korean Information Science Society Conference (KCC 2019), 2019
				<a href="https://bi.snu.ac.kr/Publications/Conferences/Domestic/KCC2019/KCC2019_jaeinKim.pdf" class="w-small-btn-outline" style="font-size: 11px;">Paper</a>
			</LI>
			<LI>Object-Aware Feature Augmentation for Robust Visual SLAM of Mobile Robots,
				H.-D Lee, C.-Y. Lee, I.-J. Hwang, and B.-T. Zhang, 2018 Proceedings of the Korean Information Science Society Conference (KSC 2018), 2018
				<a href="https://bi.snu.ac.kr/Publications/Conferences/Domestic/KSC2018/KSC2018_hdlee.pdf" class="w-small-btn-outline" style="font-size: 11px;">Paper</a>
			</LI>
			<LI>Human Recognition and Tracking for Mobile Robot using Visual Feature-based Person Re-identification Model,
				I.-J. Hwang, C.-Y. Lee, H.-D Lee, and B.-T. Zhang, 2018 Proceedings of the Korean Information Science Society Conference (KSC 2018), 2018
				<a href="https://bi.snu.ac.kr/Publications/Conferences/Domestic/KSC2018/KSC2018_ijhwang.pdf" class="w-small-btn-outline" style="font-size: 11px;">Paper</a>
			</LI>
		</UL>
	</div>
</div>

<div id="Footer">
    <p> Copyright 2024, Biointelligence Lab. Seoul National University & ARAI Lab, Pusan National University</p>
</div>
</html>

